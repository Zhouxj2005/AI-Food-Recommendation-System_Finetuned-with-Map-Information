# 基于地图API数据合成与Agent协作的Qwen3微调：构建位置感知的AI美食推荐系统
## —— 北京理工大学 NLP 课程大作业技术报告

**团队名称：** 吃点好的
**组员姓名：** 周行健（组长）、董双屹、邹明臻

---

## 摘要 (Abstract)

大语言模型（LLM）在通用知识领域表现出色，但在处理依赖实时地理位置（LBS）和特定领域实体信息的任务时，常因知识滞后或缺乏本地化数据而产生“幻觉”。本项目提出并实现了一种**基于Agent智能体合成数据并蒸馏至小模型**的完整技术路径。我们构建了一个集成高德地图API的智能体系统，自动合成了包含真实POI（兴趣点）信息的高质量指令微调数据集（1090条样本），并利用该数据集对轻量级模型 **Qwen3-0.6B** 进行了监督微调（SFT）。实验表明，通过构建“LLM-as-a-Judge”评估体系，合成数据质量与模型表现呈现强相关性（相关系数0.956），验证了在特定垂直领域通过智能体合成真实数据来提升小模型性能的有效性。

---

## 1. 项目背景与目标

### 1.1 问题陈述
通用大模型虽然具备强大的推理能力，但在面对通过用户的实时位置进行个性化服务（如“推荐我附近500米内的川菜馆”）时，往往无法获取实时物理世界的真实信息，且由于训练数据的截止时间限制，无法反映最新的地理商业信息。

### 1.2 创新点与目标
为了解决上述问题，同时响应课程关于“数据合成与知识蒸馏”的要求，本项目确立了以下目标：

1.  **Agent驱动的数据合成**：利用大模型作为“大脑”，通过调用高德地图API工具，生成基于真实地理信息的“Question-Answer”对，解决训练数据缺乏真实性的问题。
2.  **小模型知识蒸馏**：将Agent获取的外部知识（地图数据）和推理过程，通过微调内化到 Qwen3-0.6B 这样边缘端可部署的小模型中。
3.  **闭环评估体系**：构建基于阿里云百炼API的自动化评估流程，定量分析数据质量对模型性能的影响。

---

## 2. 系统架构 (System Architecture)

本项目采用模块化设计，主要包含三大核心模块：**数据生成模块 (Agent)**、**模型微调模块 (Fine-tune)** 和 **评估分析模块 (Evaluate)**。

![在此处插入系统架构图，可使用README中的目录结构截图或自绘流程图]

### 2.1 核心技术栈
- **智能体框架**：`smolagents` (用于构建Tool-use Agent)
- **外部知识源**：高德地图 API (提供LBS服务)
- **基座模型**：Qwen3-0.6B (ModelScope下载)
- **评估引擎**：阿里云百炼 API (作为裁判模型)

---

## 3. 技术实现路径

### 3.1 智能体架构与数据合成 (Data Synthesis)
这是本项目的核心创新环节。我们并未直接爬取数据，而是构建了一个**具备规划能力的Agent**来模拟真实推荐场景。

*   **Agent大脑**：利用大模型（LiteLLM调用）理解用户意图并规划工具调用序列。
*   **工具集 (Tools)**：
    1.  `GeoLocationTool`：将自然语言地名（如“北京理工大学”）转换为经纬度坐标。
    2.  `RestaurantSearchTool`：基于坐标和搜索半径（2000米），调用高德API获取真实餐厅数据（包括名称、菜系、评分、人均消费）。
    3.  `PreferenceGenTool`：随机生成多样化的用户画像（口味偏好、预算区间），保证数据的多样性。
*   **合成流程**：
    Agent 接收到生成指令后，自主执行 `ReAct` 流程：查询位置 -> 搜索周边餐厅 -> 生成符合偏好的推荐理由 -> 输出标准化的 JSON 格式数据。

**数据样例：**
> **Instruction**: 根据用户位置和偏好，推荐符合要求的餐厅
> **Question**: 我在北京良乡北京理工大学，价格需求区间为50-100，偏好川菜、健康饮食
> **Answer**: 为您推荐以下餐厅：1. 川香源（川菜）... [包含真实POI信息]

### 3.2 模型微调与蒸馏 (Model Fine-tuning)
我们将Agent合成的“教师级”数据（包含准确的地理推理）“蒸馏”给小模型。

*   **数据预处理**：编写 `prepare_data.py` 和 `transfer_data.py`，将原始JSON转换为模型所需的指令微调格式。数据集按 8:1 划分为训练集（872条）和验证集（218条）。
*   **训练配置**：
    *   模型：Qwen3-0.6B
    *   策略：全量微调（Full Fine-tuning），Batch Size=1，梯度累积4步，最大长度2048 tokens。
    *   监控：使用 Weights & Biases (WandB) 实时监控 Loss 变化。

训练数据的格式如下：

```
{
        "Instruction": "根据用户位置和偏好，推荐符合要求的餐厅",
        "Question": "我在北京市中国人民大学，预算人均100-200元，偏好东北菜、无辣不欢风格。",
        "Answer": "为您推荐以下3家餐厅：1. 山河屯铁锅炖(双榆树店) - 地址：双榆树北里2幢1号，评分4.6，距离342米，招牌麻辣锅底配大块肉食满足重口味；2. 双福园(双榆树店) - 地址：双榆树北路57号，评分4.6，距离320米，酸菜白肉锅可加辣升级，地道东北风味；3. 济州爱肉堂·双榆树店 - 地址：双榆树北里甲18号，评分4.6，距离354米，韩式烤肉搭配特制辣酱别具风味。"
    }
```

模型的训练期间的监控如下图所示：

![](./assets/wandb.png)

由**loss曲线**可以看出，在我们设计的数据集上训练8个epoch可以收敛。

完成微调之后，我们加载模型并做了多轮问答，下面是模型的回答实例：

![](./assets/answer_example.png)

可以看出，模型能够根据用户的所处的地点和口味、预算要求，给出符合条件的推荐选项。

### 3.3 自动化评估系统 (Evaluation)

为了客观评价小模型的表现，我们设计了 `RestaurantDataEvaluator` 类。

*   **评估方法**：LLM-as-a-Judge，调用阿里云百炼的高级模型作为裁判。
*   **双维度指标**：
    1.  **数据质量 (Data Quality)**：从准确性、一致性、多样性、规范性、实用性5个维度打分（满分10分）。
    2.  **模型表现 (Model Performance)**：从理解能力、推荐合理性、信息完整性、逻辑清晰性、多样性5个维度打分（满分10分）。

---

## 4. 实验结果与分析

### 4.1 数据集质量分析
经过Agent生成的1090条数据表现出极高的质量。评估结果显示，训练数据质量平均分为 **7.55/10**，其中8-9分的高质量数据占比达到 **67%**。这证明了引入地图API能有效保证数据的真实性和准确性。

<img width="2218" height="3458" alt="evaluation_visualization_v2(1)" src="https://github.com/user-attachments/assets/b8ee3463-cb87-4bab-a300-9fdd87a374b1" />


### 4.2 模型性能评估
经过8个Epoch的微调，Qwen3-0.6B 在特定任务上取得了显著进步。
*   **平均得分**：**6.64/10**。
*   **分布情况**：7-8分的回答占比 **63.4%**，说明小模型已经成功学会了推荐逻辑和格式规范，能够准确复述地理位置信息。



<img width="2200" height="1602" alt="evaluation_visualization_v2-2(1)" src="https://github.com/user-attachments/assets/40bca983-2ac0-494f-9a0d-90aeb8721a25" />
关键指标汇总
数据集信息：
  样本总数：1090
  评估时间：2025-12-08 12：31：44
训练数据质量：
  平均分：7.55
  最低分：2
  最高分：9
主要分布：
  8分(48.6%)
  8-9分占比：67.1%
原始模型表现：
  平均分：6.64
  最低分：1
  最高分：9
主要分布：
  7分(45.6%)
  7-8分占比：63.4%
□相关性分析：
  □训练数据与模型表现相关性：0.956
  □主要发现：
   1.训练数据质量保持较高水平-平均分：7.55（与前次7.58分基本持平）-8-9分占比：67.1%（质量集中）
   2.模型表现稳定
  -平均分：6.64（与前次6.66分基本持平）-7-8分占比：63.4%（表现集中）
   3.高度相关关系
  -相关性系数：0.956（接近完美正相关）-表明数据质量直接影响模型表现


### 4.3 相关性分析（关键发现）
我们对“训练数据质量”与“模型最终表现”进行了统计分析，发现二者具有极强的正相关性，相关系数高达 **0.956**。

*   **结论**：这一数据有力地证明了“Data-Centric AI”的观点——在模型参数量较小的情况下（0.6B），高质量、高真实性的合成数据是提升模型性能的关键瓶颈。

<img width="1848" height="1712" alt="evaluation_visualization(1)" src="https://github.com/user-attachments/assets/1eb2ba08-89cb-420d-8d37-03455393f92a" />

---

## 5. 总结与展望

本项目成功实现了一个端到端的“Agent数据合成 -> 小模型微调”系统。

1.  **验证了技术闭环**：证明了利用Agent工具调用能力获取外部知识（高德地图），并将其内化到小模型权重的路径是可行的。
2.  **低成本高性能**：仅使用0.6B参数量的模型，配合高质量的合成数据，即可在特定垂直领域（LBS美食推荐）达到可用的效果，具有极高的端侧部署潜力。
3.  **未来工作**：计划引入强化学习（RLHF），利用评估系统的打分作为Reward Model，进一步优化小模型的对齐效果。

---

## 6. 成员分工

*   **周行健 (组长)**：负责项目整体架构设计和Agent开发；开发 `generate_data` 模块，实现基于 `smolagents` 和高德地图API的智能体数据合成系统；撰写技术报告核心章节。
*   **董双屹**：负责 `fine_tune` 模块，搭建 Qwen3 模型微调流水线，包括数据预处理、模型训练脚本编写及超参数调试。
*   **邹明臻**：负责 `evaluate` 模块及可视化，开发基于阿里云百炼的评估脚本，进行实验数据分析与图表绘制，辅助报告撰写。
