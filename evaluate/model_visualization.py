import json
import matplotlib.pyplot as plt
import numpy as np
from collections import Counter
import matplotlib

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def load_evaluation_data(file_path):
    """åŠ è½½è¯„ä¼°æ•°æ®"""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data


def calculate_trained_model_scores(data):
    """è®¡ç®—è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†ï¼ˆåŒæƒé‡åˆå¹¶ï¼‰"""
    trained_scores = []

    for item in data:
        # èŽ·å–åŽŸå§‹è¯„åˆ†
        train_score = item.get('training_data_quality_score', 0)
        model_score = item.get('original_model_performance_score', 0)

        # åŒæƒé‡åˆå¹¶ï¼ˆç®€å•å¹³å‡ï¼‰
        combined_score = (train_score + model_score) / 2

        # å››èˆäº”å…¥åˆ°æ•´æ•°æˆ–ä¿ç•™ä¸€ä½å°æ•°
        rounded_score = round(combined_score, 1)

        # æ·»åŠ åˆ°åˆ—è¡¨ä¸­
        trained_scores.append(rounded_score)

        # ä¹Ÿå¯ä»¥åœ¨æ•°æ®ä¸­æ·»åŠ æ–°å­—æ®µ
        item['trained_model_score'] = rounded_score

    return trained_scores, data


def analyze_scores(scores):
    """åˆ†æžè¯„åˆ†æ•°æ®"""
    # è½¬æ¢ä¸ºæµ®ç‚¹æ•°ä»¥ç¡®ä¿ç»Ÿè®¡æ­£ç¡®
    scores_float = [float(score) for score in scores]

    # åŸºæœ¬ç»Ÿè®¡
    avg_score = np.mean(scores_float)
    min_score = np.min(scores_float)
    max_score = np.max(scores_float)

    # æŒ‰0.5ä¸ºåŒºé—´ç»Ÿè®¡åˆ†å¸ƒ
    bins = np.arange(0, 10.5, 0.5)
    hist, bin_edges = np.histogram(scores_float, bins=bins)

    # æŒ‰æ•´æ•°ç»Ÿè®¡ï¼ˆä¾¿äºŽå±•ç¤ºï¼‰
    int_bins = list(range(1, 11))
    int_scores = [round(score) for score in scores_float]
    int_counter = Counter(int_scores)

    # è®¡ç®—ç™¾åˆ†æ¯”
    total_count = len(scores_float)
    int_percentages = {score: count / total_count * 100 for score, count in int_counter.items()}

    return {
        'avg_score': avg_score,
        'min_score': min_score,
        'max_score': max_score,
        'total_count': total_count,
        'scores_float': scores_float,
        'int_scores': int_scores,
        'int_counter': int_counter,
        'int_percentages': int_percentages,
        'hist': hist,
        'bin_edges': bin_edges
    }


def create_visualization(analysis_results, original_data=None, save_path='trained_model_scores_visualization.png'):
    """åˆ›å»ºè®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†å¯è§†åŒ–å›¾è¡¨"""

    # åˆ›å»ºå›¾è¡¨
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†åˆ†æž\n(è®­ç»ƒæ•°æ®è´¨é‡ä¸ŽåŽŸå§‹æ¨¡åž‹è¡¨çŽ°åŒæƒé‡åˆå¹¶)',
                 fontsize=16, fontweight='bold', y=1.02)

    # æ•°æ®å‡†å¤‡
    scores_float = analysis_results['scores_float']
    int_counter = analysis_results['int_counter']
    int_percentages = analysis_results['int_percentages']
    hist = analysis_results['hist']
    bin_edges = analysis_results['bin_edges']

    # 1. è¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆæŒ‰0.5åˆ†é—´éš”ï¼‰
    ax1.hist(scores_float, bins=bin_edges, edgecolor='black', alpha=0.7, color='steelblue')
    ax1.set_title('è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†åˆ†å¸ƒï¼ˆ0.5åˆ†é—´éš”ï¼‰', fontsize=14, fontweight='bold')
    ax1.set_xlabel('è¯„åˆ†', fontsize=12)
    ax1.set_ylabel('æ ·æœ¬æ•°é‡', fontsize=12)
    ax1.grid(axis='y', alpha=0.3)

    # æ·»åŠ å¹³å‡å€¼çº¿
    ax1.axvline(analysis_results['avg_score'], color='red', linestyle='--',
                linewidth=2, label=f'å¹³å‡åˆ†: {analysis_results["avg_score"]:.2f}')
    ax1.legend()

    # 2. è¯„åˆ†åˆ†å¸ƒæ¡å½¢å›¾ï¼ˆæŒ‰æ•´æ•°ï¼‰
    int_scores_sorted = sorted(int_counter.keys())
    int_counts = [int_counter[score] for score in int_scores_sorted]
    int_percents = [int_percentages.get(score, 0) for score in int_scores_sorted]

    bars = ax2.bar(int_scores_sorted, int_counts, edgecolor='black', alpha=0.7, color='lightcoral')
    ax2.set_title('è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†åˆ†å¸ƒï¼ˆæ•´æ•°è¯„åˆ†ï¼‰', fontsize=14, fontweight='bold')
    ax2.set_xlabel('è¯„åˆ†', fontsize=12)
    ax2.set_ylabel('æ ·æœ¬æ•°é‡', fontsize=12)
    ax2.set_xticks(int_scores_sorted)
    ax2.grid(axis='y', alpha=0.3)

    # åœ¨æŸ±å­ä¸Šæ·»åŠ æ ‡ç­¾
    for bar, count, percent in zip(bars, int_counts, int_percents):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width() / 2., height + 5,
                 f'{count}\n({percent:.1f}%)', ha='center', va='bottom', fontsize=9)

    # 3. è¯„åˆ†å¯†åº¦æ›²çº¿
    from scipy.stats import gaussian_kde

    # åˆ›å»ºå¯†åº¦ä¼°è®¡
    if len(scores_float) > 1:
        density = gaussian_kde(scores_float)
        xs = np.linspace(min(scores_float) - 0.5, max(scores_float) + 0.5, 200)
        ys = density(xs)

        ax3.plot(xs, ys, color='darkgreen', linewidth=2)
        ax3.fill_between(xs, ys, alpha=0.3, color='lightgreen')

        # æ ‡è®°å¹³å‡å€¼
        ax3.axvline(analysis_results['avg_score'], color='red', linestyle='--',
                    linewidth=2, label=f'å¹³å‡åˆ†: {analysis_results["avg_score"]:.2f}')

        # æ ‡è®°ä¸­ä½æ•°
        median_score = np.median(scores_float)
        ax3.axvline(median_score, color='blue', linestyle=':',
                    linewidth=2, label=f'ä¸­ä½æ•°: {median_score:.2f}')

        ax3.set_title('è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†å¯†åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax3.set_xlabel('è¯„åˆ†', fontsize=12)
        ax3.set_ylabel('å¯†åº¦', fontsize=12)
        ax3.grid(alpha=0.3)
        ax3.legend()
    else:
        ax3.text(0.5, 0.5, 'æ•°æ®ä¸è¶³\næ— æ³•è®¡ç®—å¯†åº¦åˆ†å¸ƒ',
                 ha='center', va='center', fontsize=14, transform=ax3.transAxes)
        ax3.set_title('è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†å¯†åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')

    # 4. è¯„åˆ†ç»Ÿè®¡åˆ†æž
    ax4.axis('off')

    # è®¡ç®—æ›´å¤šç»Ÿè®¡ä¿¡æ¯
    std_score = np.std(scores_float)
    median_score = np.median(scores_float)

    # è®¡ç®—ä¸åŒåˆ†æ•°æ®µå æ¯”
    excellent = len([s for s in scores_float if s >= 8]) / len(scores_float) * 100
    good = len([s for s in scores_float if 6.5 <= s < 8]) / len(scores_float) * 100
    fair = len([s for s in scores_float if 5 <= s < 6.5]) / len(scores_float) * 100
    poor = len([s for s in scores_float if s < 5]) / len(scores_float) * 100

    # ä¸ŽåŽŸå§‹æ•°æ®å¯¹æ¯”ï¼ˆå¦‚æžœæä¾›äº†åŽŸå§‹æ•°æ®ï¼‰
    if original_data:
        # æå–åŽŸå§‹è¯„åˆ†
        train_scores = [item.get('training_data_quality_score', 0) for item in original_data]
        model_scores = [item.get('original_model_performance_score', 0) for item in original_data]

        train_avg = np.mean(train_scores)
        model_avg = np.mean(model_scores)

        comparison_text = f"""
ä¸ŽåŽŸå§‹è¯„åˆ†å¯¹æ¯”:
â€¢ è®­ç»ƒæ•°æ®å¹³å‡åˆ†: {train_avg:.2f}
â€¢ åŽŸå§‹æ¨¡åž‹å¹³å‡åˆ†: {model_avg:.2f}
â€¢ è®­ç»ƒåŽæ¨¡åž‹å¹³å‡åˆ†: {analysis_results['avg_score']:.2f}
â€¢ æå‡å¹…åº¦: {analysis_results['avg_score'] - model_avg:.2f}
        """
    else:
        comparison_text = ""

    stats_text = f"""
ðŸ“Š è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†ç»Ÿè®¡

åŸºæœ¬ç»Ÿè®¡:
â€¢ æ ·æœ¬æ€»æ•°: {analysis_results['total_count']}
â€¢ å¹³å‡åˆ†: {analysis_results['avg_score']:.2f}
â€¢ ä¸­ä½æ•°: {median_score:.2f}
â€¢ æ ‡å‡†å·®: {std_score:.2f}
â€¢ æœ€ä½Žåˆ†: {analysis_results['min_score']:.2f}
â€¢ æœ€é«˜åˆ†: {analysis_results['max_score']:.2f}

ðŸ“ˆ åˆ†æ•°æ®µåˆ†å¸ƒ:
â€¢ ä¼˜ç§€ (â‰¥8.0): {excellent:.1f}%
â€¢ è‰¯å¥½ (6.5-7.9): {good:.1f}%
â€¢ ä¸€èˆ¬ (5.0-6.4): {fair:.1f}%
â€¢ è¾ƒå·® (<5.0): {poor:.1f}%

ðŸ” ä¸»è¦ç‰¹å¾:
â€¢ ä¸»è¦åˆ†å¸ƒåŒºé—´: {np.percentile(scores_float, 25):.1f} - {np.percentile(scores_float, 75):.1f}
â€¢ å˜å¼‚ç³»æ•°: {(std_score / analysis_results['avg_score'] * 100):.1f}%

{comparison_text}

âœ… ç»“è®º:
è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†ç»¼åˆäº†æ•°æ®è´¨é‡å’ŒåŽŸå§‹è¡¨çŽ°ï¼Œ
å¹³å‡åˆ†{analysis_results['avg_score']:.2f}ï¼Œ
{excellent:.1f}%çš„æ ·æœ¬è¾¾åˆ°ä¼˜ç§€æ°´å¹³ã€‚
"""

    ax4.text(0.05, 0.5, stats_text, fontsize=11,
             verticalalignment='center',
             bbox=dict(boxstyle='round', facecolor='lightyellow',
                       alpha=0.7, edgecolor='gold', linewidth=2))

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()

    # ä¿å­˜å›¾è¡¨
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()

    return fig


def save_enhanced_data(data, output_path='enhanced_evaluation_result.json'):
    """ä¿å­˜å¢žå¼ºåŽçš„æ•°æ®ï¼ˆåŒ…å«è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†ï¼‰"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"å¢žå¼ºåŽçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    # æ–‡ä»¶è·¯å¾„
    json_file = 'evaluation_results.json'

    try:
        # 1. åŠ è½½æ•°æ®
        print("æ­£åœ¨åŠ è½½æ•°æ®...")
        data = load_evaluation_data(json_file)
        print(f"æˆåŠŸåŠ è½½ {len(data)} æ¡è®°å½•")

        # 2. è®¡ç®—è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†
        print("æ­£åœ¨è®¡ç®—è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†...")
        trained_scores, enhanced_data = calculate_trained_model_scores(data)

        # 3. åˆ†æžè¯„åˆ†
        print("æ­£åœ¨åˆ†æžè¯„åˆ†æ•°æ®...")
        analysis_results = analyze_scores(trained_scores)

        # 4. åˆ›å»ºå¯è§†åŒ–
        print("æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        fig = create_visualization(analysis_results, data)

        # 5. ä¿å­˜å¢žå¼ºåŽçš„æ•°æ®
        save_enhanced_data(enhanced_data)

        # 6. æ‰“å°è¯¦ç»†ç»Ÿè®¡
        print("\n" + "=" * 70)
        print("è®­ç»ƒåŽæ¨¡åž‹è¯„åˆ†è¯¦ç»†ç»Ÿè®¡")
        print("=" * 70)
        print(f"å¹³å‡åˆ†: {analysis_results['avg_score']:.2f}")
        print(f"ä¸­ä½æ•°: {np.median(analysis_results['scores_float']):.2f}")
        print(f"æ ‡å‡†å·®: {np.std(analysis_results['scores_float']):.2f}")
        print(f"è¯„åˆ†èŒƒå›´: {analysis_results['min_score']:.2f} - {analysis_results['max_score']:.2f}")
        print()

        print("æ•´æ•°è¯„åˆ†åˆ†å¸ƒ:")
        for score in sorted(analysis_results['int_counter'].keys()):
            count = analysis_results['int_counter'][score]
            percent = analysis_results['int_percentages'].get(score, 0)
            print(f"  {score}åˆ†: {count}ä¸ª ({percent:.1f}%)")

        print("\n" + "=" * 70)

    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {json_file}")
        print("è¯·ç¡®ä¿ evaluation_result.json æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹")
    except json.JSONDecodeError:
        print(f"é”™è¯¯: {json_file} æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {str(e)}")


# å¦‚æžœç›´æŽ¥è¿è¡Œæ­¤è„šæœ¬ï¼Œæ‰§è¡Œä¸»å‡½æ•°
if __name__ == "__main__":
    main()